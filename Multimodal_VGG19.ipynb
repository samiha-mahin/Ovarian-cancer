{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5AFlRZBpElyzUIzFApGuV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samiha-mahin/Ovarian-cancer/blob/main/Multimodal_VGG19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0KgFaKgn6GZ",
        "outputId": "ac180a4e-de2c-423a-8bcd-6193b46fe832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.1)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "NOtOxX42o9vH",
        "outputId": "cd67e21e-b79d-411d-bcd1-b0ec2e4fad4d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d4bbb62e-55f5-4561-82e7-fcc428883e82\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d4bbb62e-55f5-4561-82e7-fcc428883e82\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"samihamuntahamahin\",\"key\":\"1ad5aaba9143fbd38da418ad8d278398\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "8A7oCpf8o95i"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list -s \"ovarian cancer\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFnXnYYFo-Lw",
        "outputId": "590ace27-0805-49d8-d7bf-7bf3972db795"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                             title                                                      size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
            "--------------------------------------------------------------  --------------------------------------------------  -----------  --------------------------  -------------  ---------  ---------------  \n",
            "saurabhshahane/predict-ovarian-cancer                           Predict Ovarian Cancer                                   322564  2021-02-06 08:15:47.360000           2920         47  0.7058824        \n",
            "yoshifumimiya/6-ovarian-cancer-datasets                         7 ovarian cancer datasets                             239456735  2024-04-21 13:37:49.933000           3571         49  0.7647059        \n",
            "sunilthite/ovarian-cancer-classification-dataset                Ovarian Cancer Subtype Classification                3554471607  2023-10-31 08:34:17.390000           1652         39  1.0              \n",
            "jirkaborovec/tiles-of-ovarian-cancer-subtype                    UBC-OCEAN: Tiles 🖽 of 🔬Ovarian Cancer               13810976172  2023-11-19 08:42:32.203000            184         30  0.8125           \n",
            "sohier/ubc-ovarian-cancer-competition-supplemental-masks        UBC Ovarian Cancer Competition Supplemental Masks     372839656  2023-11-16 22:41:05.027000           1444         22  0.5              \n",
            "jirkaborovec/tiles-of-cancer-2048px-scale-0-25                  UBC-OCEAN: Tiles🖽 of Cancer🔬 2048px|scale*0.25      53076235140  2023-11-08 05:33:17.887000           1000         63  0.875            \n",
            "alexandervc/scrnaseq-ovarian-cancer-ascites-natmed2020          scRNA-seq  ovarian cancer ascites NatMed2020          162581577  2022-05-15 20:37:57.277000             79         13  0.625            \n",
            "peymannejat/ovarian-cancer-pathology-patches                    Ovarian Cancer Pathology Patches                    18237659589  2023-02-02 22:14:02.850000            431         14  0.75             \n",
            "toddgardiner/ovariancancertma-stanforddatabase                  OvarianCancerTMA-StanfordDatabase                      58553193  2023-12-29 08:10:23.267000            378         29  0.7058824        \n",
            "jirkaborovec/ubc-ocean-tiles-w-masks-2048px-scale-0-25          UBC-OCEAN: Tiles🖽 w/ masks🔬 2048px | scale 0.25     19058059551  2023-11-22 18:17:53.310000            488         39  0.8235294        \n",
            "yoshifumimiya/ovarian-cancer-tcga                               ovarian cancer (TCGA)                                  60177461  2023-06-04 17:48:34.417000            108          7  0.3529412        \n",
            "antimoni/cancer-deaths-by-country-and-type-1990-2016            Cancer Deaths by Country and Type (1990-2016) 🧮💀         971143  2023-09-13 13:03:54.623000           1381         45  0.9411765        \n",
            "dheerajmpai/ubs-ocean-split-4-cc2                               UBC OCEAN Split 4 (Class CC- Part 2)                77824278070  2023-10-09 14:56:35.773000            122          6  0.875            \n",
            "alexandervc/scrnaseq-highgrade-serous-ovarian-cancer-hgsoc      scRNA-seq high-grade serous ovarian cancer (HGSOC)    118808148  2022-05-15 22:13:46.043000             45          7  0.5882353        \n",
            "rdhenkawat/ovarian-cancer                                       ovarian cancer                                          3772400  2022-05-05 18:06:13.077000            118          1  0.3125           \n",
            "bitsnpieces/ovarian-cancer-and-subtypes-dataset-histopathology  Ovarian Cancer & Subtypes Dataset Histopathology       87194961  2023-12-24 01:04:39.270000            388          2  0.625            \n",
            "aliabedimadiseh/breast-cancer-genes                             Breast cancer genes                                      489441  2023-05-04 18:27:12.530000            285          9  0.9411765        \n",
            "hansoullee/platinum-resistant-ovarian-cancer-clinical-trials    Platinum Resistant Ovarian Cancer Clinical Trials        149951  2022-02-06 02:00:19.320000            205          5  0.47058824       \n",
            "dagobertopanassol/ubc-red-green-cells-croped-in-photoshop       UBC red green cells croped in photoshop              1104694961  2023-12-31 01:04:47.813000             19          5  0.9411765        \n",
            "dantee/trained-clam-for-ovarian-cancer                          Trained CLAM for Ovarian Cancer                        14730125  2024-02-09 10:22:59.387000             31          1  0.4117647        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d bitsnpieces/ovarian-cancer-and-subtypes-dataset-histopathology --unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk5XaqXepFbu",
        "outputId": "3d7b30ce-626f-41c2-8901-31ed1cde1d15"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/bitsnpieces/ovarian-cancer-and-subtypes-dataset-histopathology\n",
            "License(s): CC-BY-SA-4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# --------------------------\n",
        "# Define Dataset Paths and Classes\n",
        "# --------------------------\n",
        "IMG_SIZE = 224\n",
        "DATASET_PATH = \"OvarianCancer\"  # Image Dataset path\n",
        "classes = [\"Mucinous\", \"Non_Cancerous\", \"Endometri\", \"Serous\", \"Clear_Cell\"]\n",
        "class_mapping = {class_name: i for i, class_name in enumerate(classes)}\n",
        "\n",
        "# --------------------------\n",
        "# Load Image Data\n",
        "# --------------------------\n",
        "X_images, y_labels = [], []\n",
        "\n",
        "for class_name in classes:\n",
        "    class_path = os.path.join(DATASET_PATH, class_name)\n",
        "\n",
        "    if not os.path.exists(class_path):\n",
        "        continue  # Skip if folder doesn't exist\n",
        "\n",
        "    for img_name in os.listdir(class_path):\n",
        "        img_path = os.path.join(class_path, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue  # Skip unreadable images\n",
        "\n",
        "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "        img = tf.keras.applications.vgg19.preprocess_input(img)  # Preprocess for VGG19\n",
        "        X_images.append(img)\n",
        "        y_labels.append(class_mapping[class_name])  # Assign label\n",
        "\n",
        "X_images = np.array(X_images)\n",
        "y_labels = to_categorical(y_labels, num_classes=len(classes))  # One-hot encode labels\n",
        "\n",
        "# --------------------------\n",
        "# Load and Preprocess Tabular Data\n",
        "# --------------------------\n",
        "df = pd.read_csv(\"Ovarian_patient_data.csv\")  # Replace with your actual CSV file path\n",
        "df.columns = df.columns.str.strip().str.replace(\" \", \"_\").str.lower()\n",
        "features = ['age', 'ca125', 'cancerstage', 'bmi']  # Use relevant features\n",
        "df = df.dropna(subset=features).reset_index(drop=True)\n",
        "df = df.iloc[:len(X_images)]  # Align tabular data with image data\n",
        "\n",
        "# Normalize the tabular data\n",
        "scaler = StandardScaler()\n",
        "X_tabular = scaler.fit_transform(df[features].values)\n",
        "\n",
        "# --------------------------\n",
        "# Train-test split\n",
        "# --------------------------\n",
        "X_train_img, X_test_img, X_train_tab, X_test_tab, y_train, y_test = train_test_split(\n",
        "    X_images, X_tabular, y_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# --------------------------\n",
        "# Define the Image Model (VGG19)\n",
        "# --------------------------\n",
        "base_model = VGG19(weights=\"imagenet\", include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "# Freeze all layers of VGG19\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers on top of VGG19\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# --------------------------\n",
        "# Define the Tabular Model\n",
        "# --------------------------\n",
        "tab_input = tf.keras.Input(shape=(X_tabular.shape[1],), name=\"tabular_input\")\n",
        "y = Dense(64, activation=\"relu\")(tab_input)\n",
        "y = Dense(32, activation=\"relu\")(y)\n",
        "\n",
        "# --------------------------\n",
        "# Combine Image and Tabular Models\n",
        "# --------------------------\n",
        "combined = tf.keras.layers.concatenate([x, y])\n",
        "z = Dense(64, activation=\"relu\")(combined)\n",
        "output = Dense(len(classes), activation=\"softmax\")(z)\n",
        "\n",
        "# --------------------------\n",
        "# Compile the Model\n",
        "# --------------------------\n",
        "model = Model(inputs=[base_model.input, tab_input], outputs=output)\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# --------------------------\n",
        "# Callbacks\n",
        "# --------------------------\n",
        "lr_scheduler = ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.5, patience=5, verbose=1)\n",
        "checkpoint = ModelCheckpoint(\"best_model_multimodal.h5\", monitor=\"val_accuracy\", save_best_only=True, verbose=1)\n",
        "\n",
        "# --------------------------\n",
        "# Data Augmentation (For Image Data)\n",
        "# --------------------------\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    [X_train_img, X_train_tab],\n",
        "    y_train,\n",
        "    validation_data=([X_test_img, X_test_tab], y_test),\n",
        "    epochs=20,  # Adjust the number of epochs\n",
        "    batch_size=8,  # Batch size (adjust as needed)\n",
        "    verbose=1,\n",
        "    callbacks=[lr_scheduler, checkpoint]\n",
        ")\n",
        "\n",
        "# --------------------------\n",
        "# Evaluate the Model\n",
        "# --------------------------\n",
        "model.load_weights(\"best_model_multimodal.h5\")\n",
        "loss, acc = model.evaluate([X_test_img, X_test_tab], y_test)\n",
        "print(f\"\\n✅ Best Multimodal Accuracy: {acc * 100:.2f}%\")\n",
        "\n",
        "# --------------------------\n",
        "# Plot accuracy and loss\n",
        "# --------------------------\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"Val Accuracy\")\n",
        "plt.title(\"Accuracy over Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
        "plt.title(\"Loss over Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY6LlMscpO3E",
        "outputId": "97888e6d-1101-4a91-97f7-119e41b1c0dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Epoch 1/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.1584 - loss: 2.5411\n",
            "Epoch 1: val_accuracy improved from -inf to 0.20000, saving model to best_model_multimodal.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 8s/step - accuracy: 0.1591 - loss: 2.5383 - val_accuracy: 0.2000 - val_loss: 2.1225 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.2498 - loss: 2.1028\n",
            "Epoch 2: val_accuracy did not improve from 0.20000\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 7s/step - accuracy: 0.2500 - loss: 2.1015 - val_accuracy: 0.2000 - val_loss: 1.8439 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.2391 - loss: 2.0450\n",
            "Epoch 3: val_accuracy improved from 0.20000 to 0.27000, saving model to best_model_multimodal.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 8s/step - accuracy: 0.2400 - loss: 2.0417 - val_accuracy: 0.2700 - val_loss: 1.7133 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m12/50\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:49\u001b[0m 6s/step - accuracy: 0.2664 - loss: 1.9612"
          ]
        }
      ]
    }
  ]
}